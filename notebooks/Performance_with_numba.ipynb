{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance loops with `numba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first bit is the same as the *Intro_to_scientific_computing* notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [0.23, 0.34, 0.45, 0.25, 0.23, 0.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uppers = layers[:-1]\n",
    "lowers = layers[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcs = []\n",
    "for pair in zip(lowers, uppers):\n",
    "    rc = (pair[1] - pair[0]) / (pair[1] + pair[0])\n",
    "    rcs.append(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1929824561403509,\n",
       " -0.1392405063291139,\n",
       " 0.28571428571428575,\n",
       " 0.04166666666666665,\n",
       " -0.2068965517241379]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition, inputs, side-effects, returning, scope, docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "def compute_rc(layers):\n",
    "    \"\"\"\n",
    "    Computes reflection coefficients given\n",
    "    a list of layer impedances.\n",
    "    \"\"\"\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    rcs = []\n",
    "    for pair in zip(lowers, uppers):\n",
    "        rc = (pair[1] - pair[0]) / (pair[1] + pair[0])\n",
    "        rcs.append(rc)\n",
    "    return rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1929824561403509,\n",
       " -0.1392405063291139,\n",
       " 0.28571428571428575,\n",
       " 0.04166666666666665,\n",
       " -0.2068965517241379]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rc(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put in a file and import into a new notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Let's make a really big 'log' from random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Just like importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 5.65 s per loop\n"
     ]
    }
   ],
   "source": [
    "biglog = np.random.random(10000000)\n",
    "%timeit compute_rc(biglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the log has to be fairly big for the benchmarking to work properly, because otherwise the CPU caches the computation and this skews the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-write our function using arrays instead of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "def compute_rc_vector(layers):\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    return (lowers - uppers) / (uppers + lowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 90 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_rc_vector(biglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 times faster on my machine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: more performance with `numba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_rc_numba(layers):\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    return (lowers - uppers) / (uppers + lowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 12.52 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1 loops, best of 3: 88.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_rc_numba(biglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we'll make a fake example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rc_slow(layers):\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    rcs = np.zeros_like(uppers)\n",
    "    for i in range(rcs.size):\n",
    "        rcs[i] = (lowers[i] - uppers[i]) / (uppers[i] + lowers[i])\n",
    "    return rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 6.54 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_rc_slow(biglog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_rc_faster(layers):\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    rcs = np.zeros_like(uppers)\n",
    "    for i in range(rcs.size):\n",
    "        rcs[i] = (lowers[i] - uppers[i]) / (uppers[i] + lowers[i])\n",
    "    return rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 29.06 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1 loops, best of 3: 64.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_rc_faster(biglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can't speed up our original list-based function this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_rc_hopeful(layers):\n",
    "    \"\"\"\n",
    "    Computes reflection coefficients given\n",
    "    a list of layer impedances.\n",
    "    \"\"\"\n",
    "    uppers = layers[:-1]\n",
    "    lowers = layers[1:]\n",
    "    rcs = []\n",
    "    for pair in zip(lowers, uppers):\n",
    "        rc = (pair[1] - pair[0]) / (pair[1] + pair[0])\n",
    "        rcs.append(rc)\n",
    "    return rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 5.33 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_rc_hopeful(biglog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "<div>\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">Â© Agile Geoscience 2016</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
